{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from distributions import Categorical, DiagGaussian\n",
    "from collections import namedtuple\n",
    "\n",
    "import img_env \n",
    "\n",
    "import utils\n",
    "\n",
    "import model\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from random import randint\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the pretrained CNN\n",
    "======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_pretrained(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_pretrained, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "############ train the CNN_pretrained on MNIST ##################\n",
    "# n_epochs = 3\n",
    "# batch_size_train = 64\n",
    "# batch_size_test = 1000\n",
    "# learning_rate = 0.01\n",
    "# momentum = 0.5\n",
    "# log_interval = 10\n",
    "\n",
    "# random_seed = 1\n",
    "# torch.backends.cudnn.enabled = False\n",
    "# torch.manual_seed(random_seed)\n",
    "\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#   torchvision.datasets.MNIST('./pretrained_CNN/data/', train=True, download=True,\n",
    "#                              transform=torchvision.transforms.Compose([\n",
    "#                                torchvision.transforms.ToTensor(),\n",
    "#                                torchvision.transforms.Normalize(\n",
    "#                                  (0.1307,), (0.3081,))\n",
    "#                              ])),\n",
    "#   batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#   torchvision.datasets.MNIST('./pretrained_CNN/data/', train=False, download=True,\n",
    "#                              transform=torchvision.transforms.Compose([\n",
    "#                                torchvision.transforms.ToTensor(),\n",
    "#                                torchvision.transforms.Normalize(\n",
    "#                                  (0.1307,), (0.3081,))\n",
    "#                              ])),\n",
    "#   batch_size=batch_size_test, shuffle=True)\n",
    "    \n",
    "# CNN = CNN_pretrained()\n",
    "# optimizer_CNN = optim.SGD(CNN.parameters(), lr=learning_rate,\n",
    "#                       momentum=momentum)\n",
    "\n",
    "# train_losses = []\n",
    "# train_counter = []\n",
    "# test_losses = []\n",
    "# test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "# def train(epoch):\n",
    "#     CNN.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         optimizer_CNN.zero_grad()\n",
    "#         output = CNN(data)\n",
    "#         loss = F.nll_loss(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer_CNN.step()\n",
    "#         if batch_idx % log_interval == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.item()))\n",
    "#             train_losses.append(loss.item())\n",
    "#             train_counter.append(\n",
    "#                 (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "#             torch.save(optimizer_CNN.state_dict(), './pretrained_CNN/results/model.pth')\n",
    "#             torch.save(optimizer_CNN.state_dict(), './pretrained_CNN/results/optimizer.pth')\n",
    "            \n",
    "# def test():\n",
    "#     CNN.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in test_loader:\n",
    "# #             print (target.shape)\n",
    "# #             print (data.shape)\n",
    "#             output = CNN(data)\n",
    "#             test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "#             pred = output.data.max(1, keepdim=True)[1]\n",
    "#             correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "#             test_loss /= len(test_loader.dataset)\n",
    "#             test_losses.append(test_loss)\n",
    "#             print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#                 test_loss, correct, len(test_loader.dataset),\n",
    "#                 100. * correct / len(test_loader.dataset)))\n",
    "            \n",
    "# test()\n",
    "# for epoch in range(1, n_epochs + 1):\n",
    "#     train(epoch)\n",
    "#     test()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the pretrained CNN\n",
    "=======\n",
    "Try to classify the images emitted by our env. using the pretrained CNN\n",
    "Note: The pretrained CNN was trained on (28, 28) MNIST images, so I removed the resize to (32, 32) in img_env.py to keep the original (28, 28) image shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1416, Accuracy: 961/1000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################### load the pretrained CNN\n",
    "CNN_pretr = CNN_pretrained()\n",
    "CNN_state_dict = torch.load('./pretrained_CNN/results/model.pth')\n",
    "CNN_pretr.load_state_dict(CNN_state_dict)\n",
    "\n",
    "for param in CNN_pretr.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "env = img_env.ImgEnv('mnist', train=True, max_steps=1, channels=2, window=28, num_labels=2)\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for t in range(1000):\n",
    "        obs = env.reset()\n",
    "        data = torch.from_numpy(obs[1])\n",
    "        data = torch.from_numpy(obs[1]).float().resize_(1, 1, 28, 28).to(device)\n",
    "#         plt.imshow(obs[1])\n",
    "#         plt.show()\n",
    "        target = env.curr_label.resize_((1))\n",
    "        output = CNN_pretr(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "#         print ('target = {target}, pred = {pred}'.format(**locals()))\n",
    "test_loss /= 1000\n",
    "print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                test_loss, correct, 1000,\n",
    "                100. * correct / 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing_average(x, factor=10):\n",
    "    running_x = 0\n",
    "    for i in range(len(x)):\n",
    "        U = 1. / min(i+1, factor)\n",
    "        running_x = running_x * (1 - U) + x[i] * U\n",
    "        x[i] = running_x\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class myNet_CNNpretrained(nn.Module):\n",
    "    def __init__(self, obs_shape, action_space, recurrent_policy=False, dataset=None, resnet=False, pretrained=False):\n",
    "        super(myNet_CNNpretrained, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        if len(obs_shape) == 3: #our mnist case\n",
    "            self.base = model.CNNBase(obs_shape[0], recurrent_policy, dataset=dataset)\n",
    "        elif len(obs_shape) == 1:\n",
    "            assert not recurrent_policy, \\\n",
    "                \"Recurrent policy is not implemented for the MLP controller\"\n",
    "            self.base = MLPBase(obs_shape[0])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if action_space.__class__.__name__ == \"Discrete\": # our case\n",
    "            num_outputs = action_space.n\n",
    "            self.dist = Categorical(self.base.output_size, num_outputs)\n",
    "        elif action_space.__class__.__name__ == \"Box\":\n",
    "            num_outputs = action_space.shape[0]\n",
    "            self.dist = DiagGaussian(self.base.output_size, num_outputs)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if dataset in ['mnist', 'cifar10']:\n",
    "            self.clf = CNN_pretr\n",
    "            for param in self.clf.parameters(): # freeze the pretrained CNN\n",
    "                param.requires_grad = False\n",
    "    \n",
    "        self.state_size = self.base.state_size\n",
    "\n",
    "    def forward(self, inputs, states, masks):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def act(self, inputs, states, masks, deterministic=False):\n",
    "        actor_features, states = self.base(inputs, states, masks)\n",
    "        self.actor_features = actor_features\n",
    "        dist = self.dist(actor_features)\n",
    "        Q_values = dist.logits\n",
    "        \n",
    "        if deterministic:\n",
    "            action = dist.mode()\n",
    "        else:\n",
    "            action = dist.sample()\n",
    "\n",
    "        action_log_probs = dist.log_probs(action)\n",
    "\n",
    "        if self.dataset in img_env.IMG_ENVS:\n",
    "            input_CNN = torch.from_numpy(states[1]).float().resize_(1, 1, 28, 28).to(device)\n",
    "            with torch.no_grad():\n",
    "                clf_proba = self.clf(input_CNN)\n",
    "                classif = clf_proba.data.max(1, keepdim=True)[1]\n",
    "#                 print (clf_proba)\n",
    "#                 print (classif)\n",
    "#                 print (clf_proba.gather(1, classif))\n",
    "            \n",
    "            action = torch.cat([action, classif], 1)\n",
    "            action_log_probs += clf_proba.gather(1, classif)\n",
    "\n",
    "        return action, Q_values, clf_proba, action_log_probs, states #dist.logits = Q values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replay Memory\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward', 'curr_label'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization: ToDo\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training ....\n",
    "-------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [10, 2, 5, 5], but got 3-dimensional input of size [2, 28, 28] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-84970ee6ebb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcurr_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mactionS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_log_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mactionS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactionS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mclass_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactionS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-079b7df53775>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, inputs, states, masks, deterministic)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mactor_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/OnGoingWork/AutoML_as_RL_game/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, states, masks)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gru'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [10, 2, 5, 5], but got 3-dimensional input of size [2, 28, 28] instead"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    BATCH_SIZE = 128\n",
    "    NUM_STEPS = 1\n",
    "    GAMMA = 1 - (1 / NUM_STEPS) # Set to horizon of max episode length\n",
    "    EPS = 0.05\n",
    "    NUM_LABELS = 2\n",
    "    WINDOW_SIZE = 28\n",
    "    NUM_EPISODES = 1000\n",
    "    TARGET_UPDATE = 10\n",
    "\n",
    "    env = img_env.ImgEnv('mnist', train=True, max_steps=NUM_STEPS, channels=2, window=WINDOW_SIZE, num_labels=NUM_LABELS)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    net = myNet_CNNpretrained(\\\n",
    "        obs_shape=env.observation_space.shape, \\\n",
    "        action_space=env.action_space, dataset='mnist', pretrained=True).to(device)\n",
    "    memory = ReplayMemory(10000)\n",
    "\n",
    "    total_rewards = {}\n",
    "    episode_durations = {}\n",
    "    loss_classification = {}\n",
    "\n",
    "\n",
    "    for i_episode in range(NUM_EPISODES):\n",
    "        total_reward_i = 0\n",
    "        observation = env.reset()\n",
    "        curr_label = env.curr_label.item()\n",
    "        for t in range(NUM_STEPS): \n",
    "            actionS, Q_values, clf_proba, action_log_probs, states = net.act(inputs=torch.from_numpy(observation).float().to(device), \\\n",
    "                states=observation, masks=observation[1])\n",
    "            actionS = actionS.cpu().numpy()[0]\n",
    "            class_pred = actionS[1]\n",
    "            last_observation = observation\n",
    "            rand = np.random.rand()\n",
    "            if rand < EPS:\n",
    "                actionS = np.array(\n",
    "                    [np.random.choice(range(4)), np.random.choice(range(NUM_LABELS))])\n",
    "            action = actionS[0]\n",
    "            observation, reward, done, info = env.step(actionS)\n",
    "            total_reward_i = reward + GAMMA*total_reward_i\n",
    "            memory.push(torch.from_numpy(last_observation), torch.from_numpy(actionS), \\\n",
    "                torch.from_numpy(observation), torch.tensor([reward]).float(), torch.tensor([curr_label]))\n",
    "            print ('t = %i: action = %i, label = %i, class_pred = %i, reward = %f'%(t, action, curr_label, class_pred, reward))\n",
    "#             optimize_myNet(net, curr_label, optimizer_clf, BATCH_SIZE)\n",
    "\n",
    "            if done:\n",
    "    # \t\t\t\t# print ('Done after %i steps'%(t+1))\n",
    "                break\n",
    "        \n",
    "        loss_classification_i = F.nll_loss(clf_proba, env.curr_label.unsqueeze_(dim=0).to(device))\n",
    "\n",
    "        if curr_label in total_rewards.keys():\n",
    "            total_rewards[curr_label].append(total_reward_i)\n",
    "            episode_durations[curr_label].append(t)\n",
    "            loss_classification[curr_label].append(loss_classification_i)\n",
    "        else:\n",
    "            total_rewards[curr_label] = [total_reward_i]\n",
    "            episode_durations[curr_label] = [t]\n",
    "            loss_classification[curr_label] = [loss_classification_i]\n",
    "    plt.title('Class 0')\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Episode_Duration')\n",
    "    durations_t = torch.tensor(episode_durations[0], dtype=torch.float)\n",
    "    plt.plot(smoothing_average(durations_t.numpy()))\n",
    "\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Rewards')\n",
    "    total_rewards_t = torch.tensor(total_rewards[0], dtype=torch.float)\n",
    "    plt.plot(smoothing_average(total_rewards_t.numpy()))\n",
    "\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.ylim(top=1)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Loss Classification')\n",
    "    loss_classification_t = torch.tensor(loss_classification[0], dtype=torch.float)\n",
    "    plt.plot(smoothing_average(loss_classification_t.numpy()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
